#!/bin/bash

# --- SLURM Configuration (Clus 10-Node Cluster) ---
#SBATCH --job-name=laplace_experiment
#SBATCH --output=../results/laplace_run_clus_%j.log
#SBATCH --error=../results/laplace_run_clus_%j.err
#SBATCH --partition=nodo.q
#SBATCH --nodes=10
#SBATCH --mail-type=END,FAIL
#SBATCH --mail-user=1733432@uab.cat
#SBATCH --ntasks-per-node=12
#SBATCH --time=00:30:00

# --- Dynamic Path Setup ---
# Assumes you run 'sbatch' from the 'scripts' folder.
PROJECT_ROOT=$( cd -- "${SLURM_SUBMIT_DIR}/../" &> /dev/null && pwd )

# --- File Structure Paths ---
SRC_DIR="${PROJECT_ROOT}/src"
RESULTS_DIR="${PROJECT_ROOT}/results"

SRC_SEQ="${SRC_DIR}/laplace_seq.c"
SRC_MPI="${SRC_DIR}/laplace_mpi.c"

BIN_SEQ="${PROJECT_ROOT}/laplace_seq_bin"
BIN_MPI="${PROJECT_ROOT}/laplace_mpi_bin"

CSV_FILE="${RESULTS_DIR}/laplace_timings_clus_${SLURM_JOB_ID}.csv"

# --- Experiment Configuration ---
SIZES="1024 2048 4096 8192 16384 32768 65536"
PROCESSES="2 4 8 12 18 24 36 48 72 96 120"

# --- Setup ---
mkdir -p "${RESULTS_DIR}"

echo "--- SLURM JOB ${SLURM_JOB_ID} ---"
echo "PROJECT_ROOT: ${PROJECT_ROOT}"
echo "Running on 10-node [nodo.q] (12-core nodes)"
echo "Nodes: ${SLURM_JOB_NODELIST}"

# --- Load Modules ---
echo "Loading modules..."
module load gcc/12.2.1
module load openmpi/4.1.1
echo "Modules loaded."

# --- Compilation ---
echo "--- Compiling Codes ---"
mpicc -O2 -lm "${SRC_SEQ}" -o "${BIN_SEQ}"
if [ $? -ne 0 ]; then echo "Sequential compilation FAILED."; exit 1; fi

mpicc -O2 -lm "${SRC_MPI}" -o "${BIN_MPI}"
if [ $? -ne 0 ]; then echo "MPI compilation FAILED."; exit 1; fi
echo "Compilation successful."

# --- Initialize CSV ---
echo "type,matrix_size,processes,nodes,time_seconds,speedup" > "${CSV_FILE}"

# --- Run Experiments ---
echo ""
echo "--- Running Experiments & Generating Report ---"

for size in ${SIZES}; do
    echo ""
    echo "=================================================================================="
    echo "  Benchmark for Matrix Size: ${size}x${size}"
    echo "=================================================================================="

    # 1. Get Sequential Baseline
    echo "Running sequential baseline..."
    SEQ_TIME=$(mpirun -np 1 "${BIN_SEQ}" ${size} | head -n 1)
    echo "Sequential Time: ${SEQ_TIME} s"
    echo ""

    # 2. Print Table Header
    printf "%-15s %-10s %-10s %-15s %-15s %-10s\n" \
      "Matrix Size" "Processes" "Nodes" "Seq Time (s)" "Par Time (s)" "Speedup"
    printf "%-15s %-10s %-10s %-15s %-15s %-10s\n" \
      "---------------" "----------" "----------" "---------------" "---------------" "----------"

    # 3. Print Baseline Row
    printf "%-15s %-10s %-10s %-15s %-15s %-10s\n" \
      "${size}x${size}" "1" "1" "${SEQ_TIME}" "---" "1.00"
    echo "sequential,${size},1,1,${SEQ_TIME},1.00" >> "${CSV_FILE}"

    # 4. Loop through Parallel Runs
    for procs in ${PROCESSES}; do
        TASKS_PER_NODE=${SLURM_NTASKS_PER_NODE:-12}
        NODES_USED=$(( (${procs} + ${TASKS_PER_NODE} - 1) / ${TASKS_PER_NODE} ))
        
        MPI_TIME=$(mpirun -np ${procs} "${BIN_MPI}" ${size} | head -n 1)
        
        if [[ -n "$MPI_TIME" && $(echo "$MPI_TIME > 0" | bc -l) -eq 1 ]]; then
            SPEEDUP=$(awk "BEGIN {printf \"%.2f\", $SEQ_TIME / $MPI_TIME}")
        else
            MPI_TIME="Error"
            SPEEDUP="Error"
        fi

        printf "%-15s %-10s %-10s %-15s %-15s %-10s\n" \
          "${size}x${size}" "${procs}" "${NODES_USED}" "${SEQ_TIME}" "${MPI_TIME}" "${SPEEDUP}"
        echo "mpi,${size},${procs},${NODES_USED},${MPI_TIME},${SPEEDUP}" >> "${CSV_FILE}"
    done
done

# --- Cleanup ---
echo ""
rm -f "${BIN_SEQ}" "${BIN_MPI}"
echo "--- Experiment Complete ---"
echo "End time: $(date)"