=========================================
OpenMP P5 Manual Solution vs Sequential Baseline Test
Job started at: Thu Oct 30 23:40:57 CET 2025
Running on node: aolin-gpu-1.uab.cat
=========================================

Compiling programs...
Compilation successful!

=========================================
Test Configuration:
  N = 20000
  REP = 250000
=========================================

=========================================
Running Sequential Baseline (Prg_baseline)
=========================================
Inputs: N= 20000, Rep= 250000
Outputs: v= 4.975208318887e+04, A[19999]= 3.253282124495e+08
Execution time: 56.3341 seconds
Sequential Baseline Time: 56.3341s
Sequential Baseline Output: Outputs: v= 4.975208318887e+04, A[19999]= 3.253282124495e+08

=========================================
Performance Testing with P5 Solution (PrgPAR_P5)
=========================================

--- Testing with 1 threads ---
Inputs: N= 20000, Rep= 250000, Max Threads= 1 (P5 Manual Solution)
Outputs (P5 Solution): v= 4.994088195849e+04, A[19999]= 3.247076879748e+08
NOTE: Values may differ from baseline due to manual parallelization logic.
Execution time: 55.9023 seconds
  (Parallel 1-thread baseline for this run)
  Speedup vs 1-thread parallel: 1.00x
  Parallel Efficiency:          100.00%
  Speedup vs sequential code:   1.01x

--- Testing with 2 threads ---
Inputs: N= 20000, Rep= 250000, Max Threads= 2 (P5 Manual Solution)
Outputs (P5 Solution): v= 4.994088195849e+04, A[19999]= 3.247076879748e+08
NOTE: Values may differ from baseline due to manual parallelization logic.
Execution time: 33.4738 seconds
  Speedup vs 1-thread parallel: 1.67x
  Parallel Efficiency:          83.50%
  Speedup vs sequential code:   1.68x

--- Testing with 4 threads ---
Inputs: N= 20000, Rep= 250000, Max Threads= 4 (P5 Manual Solution)
Outputs (P5 Solution): v= 4.994088195849e+04, A[19999]= 3.247076879748e+08
NOTE: Values may differ from baseline due to manual parallelization logic.
Execution time: 20.7071 seconds
  Speedup vs 1-thread parallel: 2.70x
  Parallel Efficiency:          67.49%
  Speedup vs sequential code:   2.72x

--- Testing with 6 threads ---
Inputs: N= 20000, Rep= 250000, Max Threads= 6 (P5 Manual Solution)
Outputs (P5 Solution): v= 4.994088195849e+04, A[19999]= 3.247076879748e+08
NOTE: Values may differ from baseline due to manual parallelization logic.
Execution time: 19.1626 seconds
  Speedup vs 1-thread parallel: 2.92x
  Parallel Efficiency:          48.62%
  Speedup vs sequential code:   2.94x

--- Testing with 8 threads ---
Inputs: N= 20000, Rep= 250000, Max Threads= 8 (P5 Manual Solution)
Outputs (P5 Solution): v= 4.994088195849e+04, A[19999]= 3.247076879748e+08
NOTE: Values may differ from baseline due to manual parallelization logic.
Execution time: 20.8659 seconds
  Speedup vs 1-thread parallel: 2.68x
  Parallel Efficiency:          33.49%
  Speedup vs sequential code:   2.70x

--- Testing with 12 threads ---
Inputs: N= 20000, Rep= 250000, Max Threads= 12 (P5 Manual Solution)
Outputs (P5 Solution): v= 4.994088195849e+04, A[19999]= 3.247076879748e+08
NOTE: Values may differ from baseline due to manual parallelization logic.
Execution time: 22.2563 seconds
  Speedup vs 1-thread parallel: 2.51x
  Parallel Efficiency:          20.93%
  Speedup vs sequential code:   2.53x

=========================================
Detailed Performance Analysis (6 threads)
=========================================
Running perf stat on P5 solution...
Inputs: N= 20000, Rep= 250000, Max Threads= 6 (P5 Manual Solution)
Outputs (P5 Solution): v= 4.994088195849e+04, A[19999]= 3.247076879748e+08
NOTE: Values may differ from baseline due to manual parallelization logic.
Execution time: 19.3218 seconds

=========================================
Performance Summary
=========================================
Sequential Baseline Time (Prg_baseline): 56.3341s
Parallel 1-Thread Time (PrgPAR_P5): 55.9023s

Sequential Baseline Output: Outputs: v= 4.975208318887e+04, A[19999]= 3.253282124495e+08
(Note: P5 solution output values are expected to differ)

Job completed at: Thu Oct 30 23:45:05 CET 2025
=========================================
